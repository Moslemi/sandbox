{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign-language-digits in Keras\n",
    "\n",
    "Target: Create a classifier that can intepret sign language for number 0 to 9.\n",
    "\n",
    "Source: https://github.com/ardamavi/Sign-Language-Digits-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# read path\n",
    "import os\n",
    "\n",
    "# tools for machine learning in Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# high-level neural networks API - running on top of TensorFlow\n",
    "import keras\n",
    "# Sequential is a linear stack of layers\n",
    "from keras.models import Sequential\n",
    "# Dense, Flatten - type of layers, Dropout - tool, which decrease chance of overfitting\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "# optimization \n",
    "from keras.optimizers import Adam, RMSprop, Adagrad, sgd\n",
    "# preprocessing\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# data visualisation, live training loss plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# computer vision module\n",
    "import cv2\n",
    "\n",
    "# time module\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Sign-Language-Digits-Dataset/Dataset/'\n",
    "classes = list(range(0,10))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for digit in classes:\n",
    "    for img_file in os.listdir(path + str(digit)):\n",
    "        img = cv2.imread(path + str(digit) + '/' + img_file)\n",
    "        if type(img) == np.ndarray:\n",
    "            X.append(cv2.resize(img,(64,64)))\n",
    "            y.append(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Sign-Language-Digits-Dataset/Examples/'\n",
    "\n",
    "X_example = []\n",
    "y_example = []\n",
    "\n",
    "for img_file in os.listdir(path):\n",
    "    img = cv2.imread(path + img_file)\n",
    "    if type(img) == np.ndarray:\n",
    "        X_example.append(cv2.resize(img,(64,64)))\n",
    "        y_example.append(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "for index,im_index in enumerate(classes):\n",
    "        img = image.load_img('Sign-Language-Digits-Dataset/Examples/example_' + str(im_index) + '.JPG')\n",
    "        plt.subplot(2, 5, index + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(index)\n",
    "        img_index =+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "X = np.array(X, dtype=np.float32) / 255\n",
    "X_example = np.array(X_example, dtype=np.float32) / 255\n",
    "y = np.array(y, np.uint8)\n",
    "y = keras.utils.np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(model_fit, key='acc', ylim=(0.8, 1.01)):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(model_fit.history[key])\n",
    "    plt.plot(model_fit.history['val_' + key])\n",
    "    plt.title('Learning Curve')\n",
    "    plt.ylabel(key.title())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend(['train', 'test'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cnn():\n",
    "    cnn = Sequential([\n",
    "        Conv2D(32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (64, 64, 3)),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(256, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    return cnn\n",
    "\n",
    "model = my_cnn()\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100- result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_example_pred = model.predict(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, probability in enumerate(y_example_pred):\n",
    "    print('{}: {}'.format(y_example[index],np.argmax(probability)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cnn_1():\n",
    "    cnn = Sequential([\n",
    "        Conv2D(32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (64, 64, 3)),\n",
    "        Conv2D(32, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(512, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    return cnn\n",
    "\n",
    "model_1 = my_cnn_1()\n",
    "model_1.summary()\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = 'Adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_1 = model_1.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_1, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_1.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cnn_2():\n",
    "    cnn = Sequential([\n",
    "        Conv2D(32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (64, 64, 3)),\n",
    "        Conv2D(32, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(256, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(124, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    return cnn\n",
    "\n",
    "model_2 = my_cnn_2()\n",
    "model_2.summary()\n",
    "model_2.compile(loss = 'categorical_crossentropy', optimizer = 'Adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_2 = model_2.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_2, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_2.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100- result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cnn_3():\n",
    "    cnn = Sequential([\n",
    "        Conv2D(32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (64, 64, 3)),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        Conv2D(64, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size = (2, 2)),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(124, activation = 'relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = my_cnn_3()\n",
    "model_3.summary()\n",
    "model_3.compile(loss = 'categorical_crossentropy', optimizer = 'Adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_3 = model_3.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_3, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_3.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferrent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = my_cnn_3()\n",
    "model_4.summary()\n",
    "model_4.compile(loss = 'categorical_crossentropy', optimizer = 'sgd' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_4 = model_4.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_4, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_4.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = my_cnn_3()\n",
    "model_5.summary()\n",
    "model_5.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_5 = model_5.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_5, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_5.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = my_cnn_3()\n",
    "model_6.summary()\n",
    "model_6.compile(loss = 'categorical_crossentropy', optimizer = 'Adagrad' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_6 = model_6.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_6, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_6.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferrent amount of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = my_cnn_3()\n",
    "model_7.summary()\n",
    "model_7.compile(loss = 'categorical_crossentropy', optimizer = 'Adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_7 = model_7.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 2,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_7, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_7.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: ', result[1])\n",
    "print('Error: %.2f%%' % (100 - result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_8 = model_7.fit(X_train, y_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 200,\n",
    "          verbose = 0,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_8, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferrent amount of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_9 = model_7.fit(X_train, y_train,\n",
    "          batch_size = 8,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_9, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_10 = model_7.fit(X_train, y_train,\n",
    "          batch_size = 1024,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(model_fit_10, key='acc', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where I have a mistake? \n",
    "\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "def error_predict(y_test, y_pred):\n",
    "    for idx, (a, b) in enumerate(zip(y_test, y_pred)):\n",
    "        if np.argmax(a) == np.argmax(b): continue\n",
    "        yield idx, np.argmax(a), tuple(np.argsort(b)[-2:])\n",
    "        \n",
    "def display_errors():\n",
    "    random_errors = random.sample(list(error_predict(y_test, y_pred)), 12)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for index, (im_index, y_test_val, (y_pred_2, y_pred_1)) in enumerate(random_errors):\n",
    "            plt.subplot(4,4,index+1)\n",
    "            plt.imshow(X_test[im_index], cmap='ocean', interpolation='none')\n",
    "            plt.title('True value: {0}\\nFirst predicted: {1}\\nSecond predicted: {2}'.format(y_test_val, y_pred_1, y_pred_2))\n",
    "            plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_errors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
